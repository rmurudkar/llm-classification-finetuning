{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishimurudkar/kaggle/llm-classification-finetuning/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load model and tokenizer once\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"  # Good model for semantic similarity\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_batch_embeddings(texts, tokenizer, model, device, batch_size=32):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        encoded_input = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        \n",
    "        # Mean pooling\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "        attention_mask = encoded_input['attention_mask']\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        batch_embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n",
    "        \n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process all texts in batches\n",
    "prompts = df['prompt'].tolist()\n",
    "responses_a = df['response_a'].tolist()\n",
    "responses_b = df['response_b'].tolist()\n",
    "\n",
    "prompt_embeddings = get_batch_embeddings(prompts, tokenizer, model, device)\n",
    "response_a_embeddings = get_batch_embeddings(responses_a, tokenizer, model, device)\n",
    "response_b_embeddings = get_batch_embeddings(responses_b, tokenizer, model, device)\n",
    "\n",
    "# Calculate similarities\n",
    "similarities_a = [cosine_similarity([p], [r])[0][0] for p, r in zip(prompt_embeddings, response_a_embeddings)]\n",
    "similarities_b = [cosine_similarity([p], [r])[0][0] for p, r in zip(prompt_embeddings, response_b_embeddings)]\n",
    "\n",
    "df['a_semantic_overlap'] = similarities_a\n",
    "df['b_semantic_overlap'] = similarities_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Create a sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# 2. Function to get sentiment scores\n",
    "def get_sentiment_score(text):\n",
    "    # Some sentiment analyzers return multiple results for longer texts\n",
    "    # Let's limit the text length to avoid this issue\n",
    "    text = text[:512]  # Most transformer models have a token limit\n",
    "    \n",
    "    result = sentiment_analyzer(text)\n",
    "    \n",
    "    # If only one result, extract the score\n",
    "    if isinstance(result, dict):\n",
    "        # Convert to positive sentiment score (0 to 1)\n",
    "        return result[\"score\"] if result[\"label\"] == \"POSITIVE\" else 1 - result[\"score\"]\n",
    "    \n",
    "    # If multiple results, average the sentiment scores\n",
    "    positive_score = sum(r[\"score\"] for r in result if r[\"label\"] == \"POSITIVE\") / len(result)\n",
    "    negative_score = sum(r[\"score\"] for r in result if r[\"label\"] == \"NEGATIVE\") / len(result)\n",
    "    \n",
    "    # Return positive sentiment proportion (0 to 1)\n",
    "    if positive_score + negative_score > 0:\n",
    "        return positive_score / (positive_score + negative_score)\n",
    "    else:\n",
    "        return 0.5  # Neutral\n",
    "\n",
    "# 3. Function to calculate sentiment similarity\n",
    "def sentiment_similarity(sentiment1, sentiment2):\n",
    "    # Simple absolute difference, inverted so higher means more similar\n",
    "    return 1.0 - abs(sentiment1 - sentiment2)\n",
    "\n",
    "# 4. Apply functions to dataframe\n",
    "# Extract sentiment scores\n",
    "df['prompt_sentiment'] = df['prompt'].apply(get_sentiment_score)\n",
    "df['response_a_sentiment'] = df['response_a'].apply(get_sentiment_score)\n",
    "df['response_b_sentiment'] = df['response_b'].apply(get_sentiment_score)\n",
    "\n",
    "# Calculate sentiment similarity\n",
    "df['a_sentiment_match'] = df.apply(lambda row: sentiment_similarity(\n",
    "    row['prompt_sentiment'], row['response_a_sentiment']), axis=1)\n",
    "df['b_sentiment_match'] = df.apply(lambda row: sentiment_similarity(\n",
    "    row['prompt_sentiment'], row['response_b_sentiment']), axis=1)\n",
    "\n",
    "# 5. Get sentiment difference between models (which model has more similar sentiment)\n",
    "df['sentiment_match_advantage_a'] = df['a_sentiment_match'] - df['b_sentiment_match']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
